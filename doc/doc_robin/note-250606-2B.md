### 核心功能和测试场景：

这个文件主要定义了几个测试函数，用于模拟不同场景下的委员会启动、事务处理和节点恢复：

1.  **`test_config()` 函数**:
    * **作用**: 网络配置。
    * **网络模型**: 它使用了 `sui_simulator` 提供的 `bimodal_latency_ms` (双峰延迟) 和 `uniform_latency_ms` (均匀延迟) 模型，来模拟真实世界中常见的网络状况，包括区域性高方差延迟和全局性高方差延迟，这些都可能导致网络分区或消息延迟。

2.  **`test_committee_start_simple()` 异步测试函数**:
    * **目的**: 验证一个简单的委员会启动和事务处理流程。
    * **测试流程**:
        * **初始化**:
            * 循环遍历 `median_based_timestamp` (基于中位数时间戳提交) 的 `true/false` 两种情况，这表示测试会分别在两种提交策略下运行。
            * 初始化 Prometheus 注册表和数据库度量系统。
            * 创建包含 10 个验证者（`NUM_OF_AUTHORITIES = 10`）的委员会和密钥对。
            * 设置 `ProtocolConfig`，特别是 `consensus_gc_depth` (共识垃圾回收深度) 和 `consensus_median_based_commit_timestamp`。
            * **注入时钟漂移**: 为前 3 个验证者（索引 0, 1, 2）分别设置 50ms, 100ms, 120ms 的时钟漂移。这是模拟真实世界中节点间时钟不完全同步的情况，用于测试共识协议对时间敏感性问题的鲁棒性。
        * **部分节点启动**:
            * 遍历委员会，除了最后一个验证者（索引 9），其他 9 个验证者都被初始化并调用 `node.start().await.unwrap()` 启动。
            * 每个启动的节点都会调用 `spawn_committed_subdag_consumer()` 来消费已提交的子 DAG。
            * 收集所有已启动节点的 `transaction_client`。
        * **提交事务**:
            * 在一个独立的 `tokio::spawn` 任务中，提交 1000 笔模拟事务 (`NUM_TRANSACTIONS = 1000`)。这些事务被循环地提交给之前收集到的 `transaction_clients`。
        * **等待共识进展**:
            * `sleep(Duration::from_secs(60)).await;`: 让网络运行 60 秒，处理事务。
        * **延迟启动节点并追赶**:
            * `authorities[NUM_OF_AUTHORITIES - 1].start().await.unwrap();`: 启动最后一个验证者（索引 9），模拟一个延迟加入或从掉线中恢复的节点。
            * `sleep(Duration::from_secs(230)).await;`: 等待 230 秒，给这个新启动的节点充足的时间来追赶网络的最新状态。
        * **断言结果**:
            * `assert!(highest_committed_index >= 80, ...)`: 检查最后一个节点的最高已处理提交索引是否至少为 80。这验证了新加入的节点能够成功追赶并达到预期的共识进度。
        * **清理**: 循环结束后，所有验证者节点会被 `authorities` 向量的 `Drop` 实现自动停止。

3.  **`test_authority_committee()` 异步测试函数**:
    * **`#[values(ConsensusNetwork::Anemo, ConsensusNetwork::Tonic)] network_type: ConsensusNetwork`**: 测试会分别在 `Anemo` 和 `Tonic` 两种网络类型下运行。
    * **`#[values(5, 10)] gc_depth: u32`**: 测试会分别在 `consensus_gc_depth` 为 5 和 10 的情况下运行，这会影响共识状态的剪枝策略。
    * **目的**: 验证一个委员会的通用启动、事务处理和节点停止/重启流程，特别关注故障注入和恢复。
    * **测试流程**:
        * **初始化**: 创建 4 个验证者（`NUM_OF_AUTHORITIES = 4`）的委员会，并初始化它们。
        * **事务提交**: 提交 15 笔模拟事务。
        * **所有节点接收提交**: 遍历所有 `commit_receivers`，等待所有提交的事务都被所有节点成功接收。这验证了在没有故障发生时的基本共识功能。
        * **停止验证者 1**:
            * `authorities.remove(index.value()).stop().await;`: 显式停止索引为 1 的验证者（`AuthorityIndex::new_for_test(1)`）。
            * `sleep(Duration::from_secs(10)).await;`: 等待 10 秒，模拟节点离线。
        * **重启验证者 1 并验证恢复**:
            * `make_authority(...)` 再次启动验证者 1，使用其原始的数据目录。
            * `sleep(Duration::from_secs(10)).await;`: 等待其追赶。
        * **停止所有验证者并退出**: 确保所有资源被正确释放。

4.  **`test_small_committee()` 异步测试函数**:
    * **`#[values(1, 2, 3)] num_authorities: usize`**: 测试会在 1、2、3 个验证者的委员会规模下运行，以验证共识在不同规模下的行为。
    * **目的**: 与 `test_authority_committee` 类似，但更侧重于小规模委员会的启动、事务处理和节点停止/重启，验证共识的基本属性在不同拜占庭容错级别下的行为。
    * **测试流程**: 与 `test_authority_committee` 类似，包括初始化、事务提交、等待所有节点接收提交、停止验证者 0、重启验证者 0、然后停止所有验证者。

5.  **`test_amnesia_recovery_success()` 异步测试函数**:
    * **`#[values(5, 10)] gc_depth: u32`**: 同样在不同 `gc_depth` 下运行。
    * **目的**: 专门测试 **失忆恢复（Amnesia Recovery）** 场景。失忆恢复是指节点丢失其全部或部分历史数据后，如何从其他节点同步数据并重新加入共识。
    * **测试流程**:
        * **初始启动**: 启动 4 个验证者。断言所有节点都启用了 `sync_last_known_own_block`，因为它们都是首次启动，数据库为空。
        * **等待区块提交**: 等待验证者 1 提交至少一个区块，确保网络活跃。
        * **停止验证者 1 和 2**:
            * `authorities.remove(&index_1).unwrap().stop().await;`: 停止验证者 1 并**移除其数据目录**（因为它被 `TempDir::new().unwrap()` 覆盖了，模拟“失忆”）。
            * `authorities.remove(&index_2).unwrap().stop().await;`: 停止验证者 2，模拟网络中少于 f+1 个验证者可用。
        * **重启验证者 1 (失忆状态)**:
            * 用**新的临时目录**重新启动验证者 1 (`TempDir::new().unwrap()`)，同时重置 `boot_counters[index_1] = 0`。这会强制它进入失忆恢复模式。
            * 由于验证者 2 仍然停止，网络可能不足以让验证者 1 成功恢复（因为无法从足够多的对等节点获取数据）。
        * **启动验证者 2 (非失忆状态)**:
            * 重新启动验证者 2，使用其**原有数据目录**，所以它不需要失忆恢复。此时，网络中重新有了足够的活节点。
        * **验证失忆恢复成功**: 等待验证者 1 成功追赶并提交区块（由它自己授权），这表明失忆恢复成功。
        * **清理**: 停止所有验证者。

6.  **`make_authority()` 辅助函数**:
    * **作用**: 一个独立的辅助函数，用于根据给定的配置参数构建并启动 `ConsensusAuthority` 实例，以及返回其 `commit_receiver` 和 `block_receiver`。
    * **参数**: 包括 `AuthorityIndex`、`db_dir`、`committee`、`keypairs`、`network_type`、`boot_counter` 和 `protocol_config`。
    * **内部逻辑**:
        * 设置 `Parameters`，将 `db_path` 指向 `db_dir`。
        * 将 `dag_state_cached_rounds` 设置为 5，`commit_sync_parallel_fetches` 为 2，`commit_sync_batch_size` 为 3。这些是优化过的参数，用于在测试中更好地暴露提交同步问题。
        * 使用 `NoopTransactionVerifier {}`，表示交易验证逻辑被简化，不进行实际验证。
        * 创建 `CommitConsumer`，用于接收已提交的子 DAG。
        * 调用 `ConsensusAuthority::start()` 启动共识验证者。
        * 返回 `ConsensusAuthority` 实例和相关的接收器。

### 总结：

* **全面验证共识协议的正确性**：在各种网络条件（延迟、时钟漂移）和节点状态（正常运行、延迟启动、失忆恢复）下，确保共识协议能够正确地达成一致并处理事务。
* **模拟真实世界场景**：通过引入时钟漂移、网络延迟以及节点停止/重启，模拟分布式系统中常见的故障模式。
* **测试追赶和恢复机制**：重点验证新加入或从故障中恢复的节点能否成功追赶网络的最新状态。
* **确保可重现性**：使用固定种子随机数生成器，使测试结果可重现，便于调试和回归测试。


---

`ConsensusAuthority` 枚举以及 `AuthorityNode` 结构体，作为**模拟环境下 Sui 共识验证者节点的核心抽象**。

### 核心概念：

* **`ConsensusAuthority` 枚举**:
    * **作用**: 作为 Sui 验证者节点实现（`AuthorityNode`）的抽象层，它隐藏了底层网络管理器（`NetworkManager`）的具体类型（`AnemoManager` 或 `TonicManager`）。
    * **枚举成员**:
        * `WithAnemo(AuthorityNode<AnemoManager>)`: 当底层网络使用 Anemo 协议时。
        * `WithTonic(AuthorityNode<TonicManager>)`: 当底层网络使用 Tonic (gRPC) 协议时。
    * **统一接口**: 实现了 `start`, `stop`, `transaction_client`, `replay_complete` 等方法，允许调用者以统一的方式与不同网络类型的验证者节点交互。

* **`AuthorityNode<N>` 结构体**:
    * **作用**: 这是 Sui 共识验证者节点的**核心运行时组件**。它管理着节点启动后的所有内部子系统，包括共识核心、网络通信、存储、事务处理等。
    * **类型参数 `N`**: `N` 必须实现 `NetworkManager<AuthorityService<ChannelCoreThreadDispatcher>>` trait，这意味着 `AuthorityNode` 是**泛型**的，可以适配不同的网络实现（如 `AnemoManager` 或 `TonicManager`）。
    * **关键字段**:
        * `context`: `Arc<Context>`，节点的全局上下文，包含委员会、参数、协议配置、度量和时钟等。
        * `start_time`: `Instant`，记录节点启动时间。
        * `transaction_client`: `Arc<TransactionClient>`，用于向本节点提交事务的客户端。
        * `synchronizer`: `Arc<SynchronizerHandle>`，状态同步模块的句柄，负责确保节点的状态与网络同步。
        * `commit_consumer_monitor`: `Arc<CommitConsumerMonitor>`，用于监控共识提交进度。
        * `commit_syncer_handle`: `CommitSyncer` 的句柄，负责同步已提交的 DAG 片段。
        * `round_prober_handle`: `RoundProber` 的句柄，如果协议配置启用，用于探测轮次。
        * `proposed_block_handler`: `JoinHandle<()>`，处理提议区块的异步任务。
        * `leader_timeout_handle`: `LeaderTimeoutTask` 的句柄，处理领导者超时。
        * `core_thread_handle`: `CoreThreadHandle`，核心共识线程的句柄。
        * `broadcaster`: `Option<Broadcaster>`，用于广播区块和签名（如果网络不支持流式传输）。
        * `subscriber`: `Option<Subscriber<N::Client, ...>>`，用于订阅其他节点广播的区块和签名（如果网络支持流式传输）。
        * `network_manager`: 泛型参数 `N` 的实例，实际的网络管理组件。
        * `sync_last_known_own_block`: `bool`，一个标志，指示节点是否需要同步其最后已知自身区块（用于失忆恢复）。

### 核心方法讲解：

1.  **`AuthorityNode::start()` 异步方法**:
    * **作用**: 这是启动一个 Sui 验证者节点的核心逻辑。它是一个异步函数，在 Tokio 运行时中执行。
    * **参数**: 接收纪元开始时间、自身索引、委员会、参数、协议配置、密钥对、时钟、事务验证器、提交消费者、Prometheus 注册表和启动计数器。
    * **前置断言和日志**: 检查自身索引的有效性，并打印详细的启动日志，包括节点索引、主机名、协议版本、纪元开始时间戳和启动计数器。
    * **上下文初始化**: 创建 `Arc<Context>`，这是节点运行所需的共享环境。
    * **指标设置**: 设置 Prometheus 指标，如 `authority_index` 和 `protocol_version`。
    * **事务处理**: 创建 `TransactionClient` 和 `TransactionConsumer`，用于处理流入的事务。
    * **核心信号**: 创建 `CoreSignals` 用于内部组件间的通信。
    * **网络管理器初始化**: 根据 `network_type`（Anemo 或 Tonic）创建对应的 `NetworkManager` (`N::new()`)。
    * **广播器/订阅者**:
        * 根据 `N::Client::SUPPORT_STREAMING`（网络客户端是否支持流式传输）来决定创建 `Broadcaster` 或 `Subscriber`。
        * `Broadcaster` 负责将本节点提议的区块广播到网络。
        * `Subscriber` 负责订阅其他节点广播的区块流。
    * **存储层**: 初始化 `RocksDBStore` 作为持久化存储。
    * **DAG 状态**: 创建 `DagState`（基于 RocksDBStore），维护 DAG 结构和共识状态。
    * **区块验证器**: 初始化 `SignedBlockVerifier`。
    * **事务认证器**: 初始化 `TransactionCertifier`，并尝试进行恢复（`transaction_certifier.recover()`）。
    * **提议区块处理器**: 创建并启动 `ProposedBlockHandler` 异步任务，用于处理提议的区块。
    * **失忆恢复逻辑**:
        * `sync_last_known_own_block` 标志的计算：当 `boot_counter` 为 0（首次启动或模拟器重启）**并且**数据库中没有已接受的区块（`highest_accepted_round() == 0`）**并且** `sync_last_known_own_block_timeout` 不为零时，此标志为 `true`。
        * 这表明节点需要尝试从其他节点同步其“最后已知自身区块”，从而实现失忆恢复。
    * **核心共识组件实例化**:
        * `BlockManager`: 管理区块的创建、验证和存储。
        * `LeaderSchedule`: 管理领导者选举。
        * `CommitObserver`: 观察共识提交。
        * `PeerRoundTracker`: 跟踪对等节点的轮次。
        * `Core`: 共识的核心逻辑，这是协议的心脏。
    * **核心线程调度器**: `ChannelCoreThreadDispatcher::start()` 启动一个独立的 Core 线程，并将 `Core` 实例运行在其中。
    * **其他异步任务启动**:
        * `LeaderTimeoutTask`: 处理领导者超时事件。
        * `CommitVoteMonitor`: 监控提交投票。
        * `Synchronizer`: 确保节点与网络同步。
        * `CommitSyncer`: 同步已提交的 DAG 片段。
        * `RoundProber`: （如果启用）探测轮次。
    * **网络服务安装**: `network_manager.install_service(network_service).await` 将 `AuthorityService` 安装到底层网络管理器中，使其能够处理来自其他节点的传入请求。
    * **日志**: 打印节点启动完成日志及耗时。
    * **返回 `Self`**: 返回一个 `AuthorityNode` 实例，其中包含了所有启动的组件。

2.  **`AuthorityNode::stop()` 异步方法**:
    * **作用**: 异步停止节点及其所有内部组件，确保资源被正确释放。
    * **停止顺序**:
        * 首先停止调用 `Core` 的组件：`Synchronizer`、`CommitSyncer`、`RoundProber`、`ProposedBlockHandler` 和 `LeaderTimeoutTask`。这确保在 Core 停止之前，所有依赖它的任务都已停止。
        * 然后停止 `Core` 本身：`self.core_thread_handle.stop().await`，这将停止区块生产和广播。
        * 接着停止广播器 (`Broadcaster`) 和订阅者 (`Subscriber`)，这些是处理出站和入站数据流的组件。
        * 最后停止 `network_manager`，这将关闭底层网络连接。
    * **指标记录**: 记录节点的总运行时间到 `uptime` 指标。

3.  **`AuthorityNode::transaction_client()` 方法**:
    * 提供 `TransactionClient` 的共享引用，允许外部调用者向本节点提交事务。

4.  **`AuthorityNode::replay_complete()` 异步方法**:
    * 通知 `commit_consumer_monitor` 重放已完成，可能用于在节点恢复后的状态同步流程中。

### 总结：

这个 `AuthorityNode` 负责：

* **全面的组件编排**: 协调共识核心、网络、存储、事务、同步等多个子系统。
* **网络泛型支持**: 通过泛型 `N` 支持不同底层网络协议（Anemo 或 Tonic）。
* **启动和停止的生命周期管理**: 精心设计的启动和停止顺序，确保资源的正确初始化和清理。
* **失忆恢复逻辑**: 内置了处理节点数据丢失后从网络中恢复状态的机制。
* **指标和日志**: 广泛使用日志和 Prometheus 指标来提供节点运行时的可观测性。


---


### `ConsensusAuthority` 枚举

`ConsensusAuthority` 枚举作为 `AuthorityNode` 的公共抽象层，允许调用者以统一的方式与不同网络类型的验证者节点（Anemo 或 Tonic）交互。它主要通过模式匹配将调用转发给内部的 `AuthorityNode` 实例。

1.  **`pub async fn start(...) -> Self`**:
    * **作用**: 这是启动一个 **Sui 共识验证者实例** 的主要入口点。
    * **参数**:
        * `network_type: ConsensusNetwork`: 指定底层网络协议是 Anemo 还是 Tonic。
        * `epoch_start_timestamp_ms: u64`: 当前纪元（Epoch）开始的时间戳（毫秒）。
        * `own_index: AuthorityIndex`: 该验证者在委员会中的索引。
        * `committee: Committee`: 当前纪元的验证者委员会信息。
        * `parameters: Parameters`: 共识模块的运行参数（如数据库路径、缓存深度等）。
        * `protocol_config: ProtocolConfig`: Sui 协议版本和相关配置。
        * `protocol_keypair: ProtocolKeyPair`: 验证者节点的协议私钥对，用于共识消息签名。
        * `network_keypair: NetworkKeyPair`: 验证者节点的网络私钥对，用于网络通信身份验证。
        * `clock: Arc<Clock>`: 模拟时钟，用于模拟测试中的时间控制。
        * `transaction_verifier: Arc<dyn TransactionVerifier>`: 事务验证器，用于验证接收到的事务。
        * `commit_consumer: CommitConsumer`: 用于接收已提交子 DAG 的消费者。
        * `registry: Registry`: Prometheus 度量注册表，用于收集节点指标。
        * `boot_counter: u64`: 节点的启动计数器，用于判断是否需要进行失忆恢复（Amnesia Recovery）。
    * **逻辑**: 根据 `network_type` 的值，选择调用 `AuthorityNode::start` 方法来启动基于 Anemo 或 Tonic 网络的 `AuthorityNode` 实例，并将其包装在 `ConsensusAuthority` 枚举中返回。

2.  **`pub async fn stop(self)`**:
    * **作用**: 异步停止当前 `ConsensusAuthority` 管理的验证者节点及其所有内部组件。
    * **逻辑**: 根据 `ConsensusAuthority` 是 `WithAnemo` 还是 `WithTonic`，将停止请求转发给相应的 `AuthorityNode` 实例的 `stop().await` 方法。这会触发底层节点的优雅关闭和资源清理。

3.  **`pub fn transaction_client(&self) -> Arc<TransactionClient>`**:
    * **作用**: 返回一个共享的 `TransactionClient` 实例，该客户端可用于向本节点提交事务。
    * **逻辑**: 将调用转发给内部 `AuthorityNode` 实例的 `transaction_client()` 方法。

4.  **`pub async fn replay_complete(&self)`**:
    * **作用**: 通知节点的提交消费者监控器（`CommitConsumerMonitor`）“重放”过程已完成。这通常在节点从持久化存储恢复数据后调用，表示历史数据已经加载完毕，可以开始处理新数据。
    * **逻辑**: 将调用转发给内部 `AuthorityNode` 实例的 `replay_complete().await` 方法。

5.  **`#[cfg(test)] fn context(&self) -> &Arc<Context>`**:
    * **作用**: （仅在测试构建时可用）返回节点上下文的共享引用。
    * **逻辑**: 仅用于测试中访问节点的内部上下文，以便检查其状态或配置。

6.  **`#[allow(unused)] fn sync_last_known_own_block_enabled(&self) -> bool`**:
    * **作用**: 检查当前节点是否启用了“同步最后已知自身区块”的机制。这与节点的失忆恢复逻辑相关。
    * **逻辑**: 将调用转发给内部 `AuthorityNode` 实例的同名方法。

### `AuthorityNode<N>` 结构体

`AuthorityNode` 结构体是 Sui 验证者节点在模拟环境中的具体实现。它封装了节点的所有运行时组件，并提供了一套管理其生命周期的方法。

1.  **`pub(crate) async fn start(...) -> Self`**:
    * **作用**: 初始化并启动一个 `AuthorityNode` 实例。这是 `ConsensusAuthority::start` 实际调用的底层启动函数。
    * **参数**: 与 `ConsensusAuthority::start` 接收的参数基本相同，但这里是具体的实现层。
    * **逻辑**:
        * **断言**: 检查 `own_index` 在 `committee` 中的有效性。
        * **日志**: 打印详细的启动信息，包括节点索引、主机名、协议版本、纪元开始时间戳和启动计数器。
        * **上下文初始化**: 创建 `Arc<Context>`，作为所有内部组件共享的上下文。
        * **指标设置**: 设置节点的 Prometheus 指标，如 `authority_index` 和 `protocol_version`。
        * **事务客户端和消费者**: 创建 `TransactionClient` 和 `TransactionConsumer`。
        * **核心信号**: 创建 `CoreSignals`，用于 `Core` 模块与其他组件间的事件通信。
        * **网络管理器**: 根据泛型 `N`（`AnemoManager` 或 `TonicManager`）创建 `network_manager` 实例，并获取 `network_client`。
        * **广播器/订阅者**:
            * 根据 `N::Client::SUPPORT_STREAMING` 标志（即底层网络是否支持流式传输），选择创建 `Broadcaster` 或 `Subscriber`。
            * `Broadcaster` 负责将本节点提议的区块广播出去。
            * `Subscriber` 负责订阅和接收其他节点广播的区块流。
        * **存储层**: 初始化 `RocksDBStore` 作为节点的持久化存储。
        * **DAG 状态**: 创建 `DagState`，用于维护共识 DAG 的内存表示，并与 `RocksDBStore` 交互。
        * **区块验证器**: 初始化 `SignedBlockVerifier`，负责验证接收到的区块的签名和内容。
        * **事务认证器**: 初始化 `TransactionCertifier`，并调用 `recover()` 方法从存储中恢复状态。
        * **提议区块处理器 (`proposed_block_handler`)**: 创建并启动一个异步任务，处理来自 `signals_receivers` 的提议区块广播信号。
        * **失忆恢复判断**: `sync_last_known_own_block` 标志的计算：
            * 如果 `boot_counter` 为 0 (首次启动或模拟器重启)；
            * **并且** `dag_state.read().highest_accepted_round() == 0` (数据库中没有已接受的区块，即 DB 是空的)；
            * **并且** `sync_last_known_own_block_timeout` 不为零 (配置中启用了超时机制)；
            * 那么 `sync_last_known_own_block` 将为 `true`，表示节点需要尝试从其他节点同步其“最后已知自身区块”来恢复状态。
        * **共识核心组件**: 初始化 `BlockManager`, `LeaderSchedule`, `CommitObserver`, `PeerRoundTracker`。
        * **`Core` 实例**: 创建 `Core` 实例，它是共识协议的主要逻辑处理器。
        * **核心线程调度器**: `ChannelCoreThreadDispatcher::start()` 启动一个独立的 Core 线程，将 `Core` 实例运行在其中，并通过通道进行通信。
        * **领导者超时任务**: `LeaderTimeoutTask::start()` 启动异步任务，监控并处理领导者超时。
        * **提交投票监控**: `CommitVoteMonitor` 用于监控提交投票。
        * **同步器**: `Synchronizer::start()` 启动状态同步模块，确保节点与网络同步。
        * **提交同步器**: `CommitSyncer::new().start()` 启动同步已提交 DAG 片段的模块。
        * **轮次探测器**: 如果协议配置启用了 `consensus_round_prober()`，则启动 `RoundProber`。
        * **网络服务**: 创建 `AuthorityService` 实例，它实现了处理来自其他节点的网络请求的服务端逻辑。
        * **安装网络服务**: `network_manager.install_service(network_service).await` 将 `AuthorityService` 安装到底层网络管理器中，使其能够处理传入的网络请求。
        * **日志**: 打印节点启动完成日志及耗时。
        * **返回 `Self`**: 返回一个包含了所有启动组件的 `AuthorityNode` 实例。

2.  **`pub(crate) async fn stop(mut self)`**:
    * **作用**: 优雅地停止 `AuthorityNode` 实例及其所有内部组件。
    * **逻辑**: 按照从上层到下层、从依赖到被依赖的顺序停止组件，以确保安全关闭：
        * 首先停止调用 `Core` 的组件：`synchronizer`、`commit_syncer_handle`、`round_prober_handle`、`proposed_block_handler` 和 `leader_timeout_handle`。
        * 然后停止 `Core` 本身：`self.core_thread_handle.stop().await`，这将停止区块生产和广播。
        * 接着停止广播器 (`Broadcaster`) 和订阅者 (`Subscriber`)。
        * 最后停止 `network_manager`，这将关闭底层网络连接。
    * **指标记录**: 记录节点的总运行时间到 `uptime` 指标。

3.  **`pub(crate) fn transaction_client(&self) -> Arc<TransactionClient>`**:
    * **作用**: 返回一个共享的 `TransactionClient` 实例的克隆。
    * **逻辑**: 简单地克隆 `self.transaction_client` 并返回。

4.  **`pub(crate) async fn replay_complete(&self)`**:
    * **作用**: 通知 `commit_consumer_monitor` 数据重放已完成。这通常发生在节点启动或恢复时，从存储中加载完所有历史数据之后。
    * **逻辑**: 调用 `self.commit_consumer_monitor.replay_complete().await`。

